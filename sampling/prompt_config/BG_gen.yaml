out_dir: "finetuned_models/BG_head"  # the path to the directory containing the trained model
start: FILE:prompts/Ti4Ga2Cu2.txt  # the prompt; can also specify a file, use as: "FILE:prompt.txt"
num_samples: 1  # number of samples to draw
max_new_tokens: 2000  # number of tokens generated in each sample
temperature: 0.8  # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions
top_k: 10  # retain only the top_k most likely tokens, clamp others to have 0 probability
seed: 1337
device: "cuda"  # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.
dtype: "bfloat16"  # 'float32' or 'bfloat16' or 'float16'
compile: False  # use PyTorch 2.0 to compile the model to be faster
target: console  # where the generated content will be sent; can also be 'file'
generated_dir: test_generated_cifs_BG #Directory of Cif files
token_resize: True  # resize token embeddings to match the checkpoint's vocab size
dataset: "BG_large_tokens"  # the path to the directory containing the dataset